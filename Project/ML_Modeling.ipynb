{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5be8d3a-c92b-4fa3-93b6-7f0b1ed7efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf59a3f2-9417-4aab-a499-c131c7ed0e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/Raw/new_approach/Weekly_Covid_Data_Population_Normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb9b5e0-7d63-4975-b48a-a2945ffabe16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['week_no', 'iso_code', 'new_cases', 'new_deaths', 'new_vaccinations',\n",
      "       'new_people_vaccinated', 'reproduction_rate', 'stringency_index',\n",
      "       'excess_mortality', 'population_density', 'median_age', 'aged_65_older',\n",
      "       'aged_70_older', 'cardiovasc_death_rate', 'diabetes_prevalence',\n",
      "       'female_smokers', 'male_smokers', 'hospital_beds_per_thousand',\n",
      "       'life_expectancy', 'human_development_index', 'population'],\n",
      "      dtype='object')\n",
      "(41184, 21)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada1e29d-45ad-4443-9b54-3eaa7ab628d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_cases                     4.595436e-06\n",
      "new_deaths                    1.225450e-07\n",
      "new_vaccinations              0.000000e+00\n",
      "new_people_vaccinated         0.000000e+00\n",
      "reproduction_rate             9.500000e-01\n",
      "stringency_index              8.796000e+01\n",
      "excess_mortality             -1.000000e+03\n",
      "population_density            4.272900e+01\n",
      "median_age                    1.960000e+01\n",
      "aged_65_older                 2.822000e+00\n",
      "aged_70_older                 1.882000e+00\n",
      "cardiovasc_death_rate         3.078460e+02\n",
      "diabetes_prevalence           1.820000e+00\n",
      "female_smokers                1.600000e+00\n",
      "male_smokers                  3.070000e+01\n",
      "hospital_beds_per_thousand    1.700000e+00\n",
      "life_expectancy               6.149000e+01\n",
      "human_development_index       5.710000e-01\n",
      "population                    1.632054e+07\n",
      "Name: 41183, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.drop([\"iso_code\", \"week_no\"], axis=1, inplace=True)\n",
    "#df.drop(columns=df.columns[0:1], axis=1, inplace=True)\n",
    "pop = df.iloc[0][\"population\"]\n",
    "last_country = df.iloc[234*176 - 1]\n",
    "print(last_country)\n",
    "cnt = df[\"population\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d279ca1-51e9-4d60-aa96-48f0e4a165b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are going to normilze the data.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = df.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c8b85b9-b33d-41f2-b11f-b66ca482ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to join datas together\n",
    "prediction_days_count = 2\n",
    "features_list = []\n",
    "X_list = []\n",
    "Y_list = []\n",
    "for i in range(234): # 234 is number of countries\n",
    "    for j in range(176): # 176 is number of weeks we have\n",
    "        row_list = df.loc[i*176 + j, :].values.flatten().tolist()\n",
    "        features_list.append(row_list)\n",
    "# print(len(features_list))\n",
    "# print((len(features_list) - prediction_days_count) + 1)\n",
    "for i in range((len(features_list) - prediction_days_count) + 1):\n",
    "    fl = features_list[i]\n",
    "    fl_len = len(features_list[i])\n",
    "    this_population = features_list[i][fl_len - 1]\n",
    "    for j in range(1, prediction_days_count):\n",
    "        if this_population == features_list[i + j][fl_len - 1]:\n",
    "            fl.extend(features_list[i + j])\n",
    "        else:\n",
    "            this_population = -1\n",
    "            break\n",
    "    if this_population != -1:\n",
    "        X_list.append(fl)\n",
    "        Y_list.append(features_list[(i + prediction_days_count) - 1][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a776d097-7e1f-44f8-9325-32afcf8b5065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40950\n",
      "40950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40950, 38)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(X_list))\n",
    "print(len(Y_list))\n",
    "np.shape(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b695b00-4be2-4361-a7f3-810dc49d92ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def train_test_splitter(X, Y, prediction_days_count, batch_count, batch_length):\n",
    "    xlen = len(X)\n",
    "    xs_count_for_each_country = int(xlen / 234)\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    Y_train = []\n",
    "    Y_test = []\n",
    "    steps = math.floor((xs_count_for_each_country - (batch_count * batch_length)) / (batch_count + 1)) \n",
    "    i = 0\n",
    "    #print(steps)\n",
    "    for i in range(234):\n",
    "        j = 0\n",
    "        for j in range((i * xs_count_for_each_country),(i * xs_count_for_each_country) + steps):\n",
    "            X_train.append(X[j])\n",
    "        #print(j)\n",
    "            Y_train.append(Y[j])\n",
    "        while(j + batch_length + steps < (i+1) * xs_count_for_each_country):\n",
    "            for k in range(j + prediction_days_count, j + batch_length - prediction_days_count):\n",
    "                X_test.append(X[k])\n",
    "                Y_test.append(Y[k])\n",
    "            j += batch_length\n",
    "            for k in range(j, j + steps):\n",
    "                X_train.append(X[k])\n",
    "                Y_train.append(Y[k])\n",
    "            j += steps + 1\n",
    "            while j < (i+1) * xs_count_for_each_country:\n",
    "                X_train.append(X[j])\n",
    "                Y_train.append(Y[j])\n",
    "                j += 1\n",
    "        #print(j)\n",
    "    ########\n",
    "    # for i in range(steps):\n",
    "    #     X_train.append(X[i])\n",
    "    # while(i + batch_length + steps < xlen):\n",
    "    #     for j in range(batch_length):\n",
    "    #         X_test.append(X[j])\n",
    "    #         Y_test.append(Y[j])\n",
    "    #     for j in range(i, i + steps):\n",
    "    #         X_train.append(X[j])\n",
    "    #         Y_train.append(Y[j])\n",
    "    #     i += batch_length + steps\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "638adfd3-a41a-435b-b2e3-61a25cb1753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_splitter(X_list, Y_list, prediction_days_count, 3, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6f75baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38610, 38) (1404, 38) (38610,) (1404,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train), np.shape(X_test), np.shape(Y_train), np.shape(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5de0ea",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa8c2c1",
   "metadata": {},
   "source": [
    "## Importing loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc5cc906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error, root_mean_squared_error, mean_absolute_error, d2_tweedie_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ddbc7",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b293cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96be8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel=\"rbf\", C=100, gamma=0.1, epsilon=0.1)\n",
    "svr_lin = SVR(kernel=\"linear\", C=100, gamma=\"auto\")\n",
    "svr_poly = SVR(kernel=\"poly\", C=100, gamma=\"auto\", degree=3, epsilon=0.1, coef0=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e593f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of SVR(C=100, gamma=0.1): 1.0\n",
      "mae of SVR(C=100, gamma=0.1): 0.0901160462533613\n",
      "mape of SVR(C=100, gamma=0.1): 63949432333455.11\n",
      "rmse of SVR(C=100, gamma=0.1): 0.09029726065944563\n",
      "tweedie of SVR(C=100, gamma=0.1): -31.371779837042958\n",
      "\n",
      "score of SVR(C=100, gamma='auto', kernel='linear'): -6.961665413380666\n",
      "mae of SVR(C=100, gamma='auto', kernel='linear'): 0.09922041788351141\n",
      "mape of SVR(C=100, gamma='auto', kernel='linear'): 67136585770106.305\n",
      "rmse of SVR(C=100, gamma='auto', kernel='linear'): 0.09922480708244777\n",
      "tweedie of SVR(C=100, gamma='auto', kernel='linear'): -34.78150159791742\n",
      "\n",
      "score of SVR(C=100, coef0=1, gamma='auto', kernel='poly'): -7.895352059218952\n",
      "mae of SVR(C=100, coef0=1, gamma='auto', kernel='poly'): 0.09933606455007674\n",
      "mape of SVR(C=100, coef0=1, gamma='auto', kernel='poly'): 67256751834455.086\n",
      "rmse of SVR(C=100, coef0=1, gamma='auto', kernel='poly'): 0.09934251515646672\n",
      "tweedie of SVR(C=100, coef0=1, gamma='auto', kernel='poly'): -34.827459893796615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svrs = [svr_rbf, svr_lin, svr_poly]\n",
    "#kernel_label = [\"RBF\", \"Linear\", \"Polynomial\"]\n",
    "#model_color = [\"m\", \"c\", \"g\"]\n",
    "\n",
    "X_tr = np.array(X_train)\n",
    "y_tr = np.array(Y_train)\n",
    "X_te = np.array(X_test)\n",
    "y_te = np.array(Y_test)\n",
    "\n",
    "for svr in (svrs):\n",
    "    y_pred= svr.fit(X_tr, y_tr).predict(X_te)\n",
    "    svr_score = svr_rbf.score( X_te, y_pred)\n",
    "\n",
    "    \n",
    "    mae = mean_absolute_error(y_te , y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_te , y_pred)\n",
    "    rmse = root_mean_squared_error(y_te , y_pred)\n",
    "    tweedie = d2_tweedie_score(y_te , y_pred , power=1)\n",
    "\n",
    "    print(f\"score of {svr}:\" , svr_score)\n",
    "    print(f\"mae of {svr}:\" , mae)\n",
    "    print(f\"mape of {svr}:\" , mape)\n",
    "    print(f\"rmse of {svr}:\" , rmse)\n",
    "    print(f\"tweedie of {svr}:\" , tweedie)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b2cda",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d681fc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae  : 0.0010645052248964655\n",
      "mape : 73889449152.31938\n",
      "rmse : 0.0028170040291258342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neigh = KNeighborsRegressor(n_neighbors=2 , p = 2)\n",
    "neigh.fit(X_tr, y_tr)\n",
    "y_pred = neigh.predict(X_te)\n",
    "\n",
    "mae = mean_absolute_error(y_te , y_pred)\n",
    "mape = mean_absolute_percentage_error(y_te , y_pred)\n",
    "rmse = root_mean_squared_error(y_te , y_pred)\n",
    "#tweedie = d2_tweedie_score(y_te , y_pred , power=1)\n",
    "\n",
    "print(f\"mae  :\" , mae)\n",
    "print(f\"mape :\" , mape)\n",
    "print(f\"rmse :\" , rmse)\n",
    "#print(f\"tweedie power 1 :\" , tweedie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e572c091",
   "metadata": {},
   "source": [
    "## Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "468f8466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae  : 1.3577169656974628e-06\n",
      "mape : 840209159.7616506\n",
      "rmse : 4.641560682577544e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X_train)\n",
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "poly.fit_transform(X_tr)\n",
    "\n",
    "mae = mean_absolute_error(y_te , y_pred)\n",
    "mape = mean_absolute_percentage_error(y_te , y_pred)\n",
    "rmse = root_mean_squared_error(y_te , y_pred)\n",
    "#tweedie = d2_tweedie_score(y_te , y_pred , power=1)\n",
    "\n",
    "print(f\"mae  :\" , mae)\n",
    "print(f\"mape :\" , mape)\n",
    "print(f\"rmse :\" , rmse)\n",
    "#print(f\"tweedie power 1 :\" , tweedie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbec15c",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "363013d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae  : 0.0028442039290177395\n",
      "mape : 2412976579165.9087\n",
      "rmse : 0.0032567660139883794\n",
      "tweedie power 1 : 0.18719293782035662\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "#from sklearn.datasets import make_regression\n",
    "\n",
    "regr = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "regr.fit(X_tr, y_tr)\n",
    "y_pred = regr.predict(X_te)\n",
    "\n",
    "mae = mean_absolute_error(y_te , y_pred)\n",
    "mape = mean_absolute_percentage_error(y_te , y_pred)\n",
    "rmse = root_mean_squared_error(y_te , y_pred)\n",
    "tweedie = d2_tweedie_score(y_te , y_pred , power=1)\n",
    "\n",
    "print(f\"mae  :\" , mae)\n",
    "print(f\"mape :\" , mape)\n",
    "print(f\"rmse :\" , rmse)\n",
    "print(f\"tweedie power 1 :\" , tweedie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c200fb6",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "15a9a8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae  : 0.00041602502429478736\n",
      "mape : 155376096166.6958\n",
      "rmse : 0.0005561307504618705\n",
      "tweedie power 1 : 0.9354688259792544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.datasets import make_regression\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "regr.fit(X_tr, y_tr)\n",
    "y_pred = regr.predict(X_te)\n",
    "regr.score(X_te, y_pred)\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_te , y_pred)\n",
    "mape = mean_absolute_percentage_error(y_te , y_pred)\n",
    "rmse = root_mean_squared_error(y_te , y_pred)\n",
    "tweedie = d2_tweedie_score(y_te , y_pred , power=1)\n",
    "\n",
    "print(f\"mae  :\" , mae)\n",
    "print(f\"mape :\" , mape)\n",
    "print(f\"rmse :\" , rmse)\n",
    "print(f\"tweedie power 1 :\" , tweedie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884bd95",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "40b8cace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae  : 1.3577169656974628e-06\n",
      "mape : 840209159.7616506\n",
      "rmse : 4.641560682577544e-06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "estimators = [\n",
    "    ('lr', RidgeCV()),\n",
    "    ('svr', LinearSVR(dual=\"auto\", random_state=42))\n",
    "]\n",
    "reg = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor(n_estimators=10,\n",
    "                                          random_state=42)\n",
    ")\n",
    "\n",
    "y_pred = reg.fit(X_tr, y_tr).predict(X_te)\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_te , y_pred)\n",
    "mape = mean_absolute_percentage_error(y_te , y_pred)\n",
    "rmse = root_mean_squared_error(y_te , y_pred)\n",
    "#tweedie = d2_tweedie_score(y_te , y_pred , power=1)\n",
    "\n",
    "print(f\"mae  :\" , mae)\n",
    "print(f\"mape :\" , mape)\n",
    "print(f\"rmse :\" , rmse)\n",
    "#print(f\"tweedie power 1 :\" , tweedie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d69c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcd6b38f",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55795a1b-aaa3-4763-b1fe-d0c4e23a7c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ns_list, train_scores, validation_scores = learning_curve(\n",
    "#                                                    estimator = SVR(**opt_svr_param), \n",
    "#                                                    X = X, y = Y, \n",
    "#                                                    train_sizes = ns_list, cv = 5,\n",
    "#                                                    scoring = 'neg_mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e7ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_scores, valid_scores = validation_curve(KNeighborsRegressor(), X, Y, \n",
    "#                                               param_name=\"n_neighbors\",\n",
    "#                                               param_range=k_list , cv=20, \n",
    "#                                               scoring = 'neg_mean_squared_error',\n",
    "#                                               verbose=1, n_jobs=-1\n",
    "#                                              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c424a7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
