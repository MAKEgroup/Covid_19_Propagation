{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5be8d3a-c92b-4fa3-93b6-7f0b1ed7efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf59a3f2-9417-4aab-a499-c131c7ed0e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"../Data/Raw/new_approach/Weekly_Covid_Data_Population_Normalized.csv\")\n",
    "df = pd.read_csv(\"../Data/Raw/new_approach/Weekly_Covid_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afb9b5e0-7d63-4975-b48a-a2945ffabe16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['week_no', 'iso_code', 'new_cases', 'new_deaths', 'new_vaccinations',\n",
      "       'new_people_vaccinated', 'reproduction_rate', 'stringency_index',\n",
      "       'excess_mortality', 'population_density', 'median_age', 'aged_65_older',\n",
      "       'aged_70_older', 'cardiovasc_death_rate', 'diabetes_prevalence',\n",
      "       'female_smokers', 'male_smokers', 'hospital_beds_per_thousand',\n",
      "       'life_expectancy', 'human_development_index', 'population'],\n",
      "      dtype='object')\n",
      "(41184, 21)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ada1e29d-45ad-4443-9b54-3eaa7ab628d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_cases                     7.500000e+01\n",
      "new_deaths                    2.000000e+00\n",
      "new_vaccinations              0.000000e+00\n",
      "new_people_vaccinated         0.000000e+00\n",
      "reproduction_rate             9.500000e-01\n",
      "stringency_index              8.796000e+01\n",
      "excess_mortality             -1.000000e+03\n",
      "population_density            4.272900e+01\n",
      "median_age                    1.960000e+01\n",
      "aged_65_older                 2.822000e+00\n",
      "aged_70_older                 1.882000e+00\n",
      "cardiovasc_death_rate         3.078460e+02\n",
      "diabetes_prevalence           1.820000e+00\n",
      "female_smokers                1.600000e+00\n",
      "male_smokers                  3.070000e+01\n",
      "hospital_beds_per_thousand    1.700000e+00\n",
      "life_expectancy               6.149000e+01\n",
      "human_development_index       5.710000e-01\n",
      "population                    1.632054e+07\n",
      "Name: 41183, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.drop([\"iso_code\", \"week_no\"], axis=1, inplace=True)\n",
    "#df.drop(columns=df.columns[0:1], axis=1, inplace=True)\n",
    "pop = df.iloc[0][\"population\"]\n",
    "last_country = df.iloc[234*176 - 1]\n",
    "print(last_country)\n",
    "cnt = df[\"population\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c8b85b9-b33d-41f2-b11f-b66ca482ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to join datas together\n",
    "prediction_days_count = 2\n",
    "features_list = []\n",
    "X_list = []\n",
    "Y_list = []\n",
    "\n",
    "for i in range(234):  # 234 is number of countries\n",
    "    for j in range(176):  # 176 is number of weeks we have\n",
    "        row_list = df.loc[i * 176 + j, :].values.flatten().tolist()\n",
    "        features_list.append(row_list)\n",
    "\n",
    "for i in range((len(features_list) - prediction_days_count) + 1):\n",
    "    fl = features_list[i]\n",
    "    fl_len = len(features_list[i])\n",
    "    this_population = features_list[i][fl_len - 1]\n",
    "    for j in range(1, prediction_days_count):\n",
    "        if this_population == features_list[i + j][fl_len - 1]:\n",
    "            fl.extend(features_list[i + j])\n",
    "        else:\n",
    "            this_population = -1\n",
    "            break\n",
    "    if this_population != -1:\n",
    "        X_list.append(fl)\n",
    "        Y_list.append(features_list[(i + prediction_days_count) - 1][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a776d097-7e1f-44f8-9325-32afcf8b5065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40950\n",
      "40950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40950, 38)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(X_list))\n",
    "print(len(Y_list))\n",
    "np.shape(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d10ddaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are going to normalize the data.\n",
    "from sklearn import preprocessing\n",
    "x_df = pd.DataFrame(X_list)\n",
    "min_max_scaler_X = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler_X.fit_transform(x_df)\n",
    "\n",
    "y_df = pd.DataFrame(Y_list)\n",
    "min_max_scaler_Y = preprocessing.MinMaxScaler()\n",
    "y_scaled = min_max_scaler_Y.fit_transform(y_df)\n",
    "\n",
    "X_scaled_list = x_scaled.tolist()\n",
    "Y_scaled_list = y_scaled.tolist()\n",
    "\n",
    "#df = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b695b00-4be2-4361-a7f3-810dc49d92ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def train_test_splitter(X, Y, prediction_days_count, batch_count, batch_length):\n",
    "    xlen = len(X)\n",
    "    xs_count_for_each_country = int(xlen / 234)\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    Y_train = []\n",
    "    Y_test = []\n",
    "    steps = math.floor((xs_count_for_each_country - (batch_count * batch_length)) / (batch_count + 1)) \n",
    "    i = 0\n",
    "    for i in range(234):\n",
    "        j = 0\n",
    "        for j in range((i * xs_count_for_each_country), (i * xs_count_for_each_country) + steps):\n",
    "            X_train.append(X[j])\n",
    "            Y_train.append(Y[j])\n",
    "        while(j + batch_length + steps < (i+1) * xs_count_for_each_country):\n",
    "            for k in range(j + prediction_days_count, j + batch_length - prediction_days_count):\n",
    "                X_test.append(X[k])\n",
    "                Y_test.append(Y[k])\n",
    "            j += batch_length\n",
    "            for k in range(j, j + steps):\n",
    "                X_train.append(X[k])\n",
    "                Y_train.append(Y[k])\n",
    "            j += steps + 1\n",
    "            while j < (i+1) * xs_count_for_each_country:\n",
    "                X_train.append(X[j])\n",
    "                Y_train.append(Y[j])\n",
    "                j += 1\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "638adfd3-a41a-435b-b2e3-61a25cb1753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_splitter(X_scaled_list, Y_scaled_list, prediction_days_count, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d90b2d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6f75baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (30888, 38) ,X_val: (7722, 38) ,X_test: (1404, 38) ,Y_train: (30888, 1) ,Y_val: (7722, 1) ,Y_test: (1404, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\", np.shape(X_train),\n",
    "      \",X_val:\" , np.shape(X_val),\n",
    "      \",X_test:\", np.shape(X_test),\n",
    "\n",
    "      \",Y_train:\" ,np.shape(Y_train),\n",
    "      \",Y_val:\", np.shape(Y_val),\n",
    "      \",Y_test:\", np.shape(Y_test)\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26d7fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.array(X_train)\n",
    "y_tr = np.array(Y_train)\n",
    "X_te = np.array(X_test)\n",
    "y_te = np.array(Y_test)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a40d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale predictions and true values back to original scale\n",
    "def rescale_data(scaler, data):\n",
    "    return scaler.inverse_transform(np.array(data).reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffed55f-a8bf-44bf-babe-a378c99d42ab",
   "metadata": {},
   "source": [
    "# Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91719d72-f706-4a78-97ff-c3b5117ae06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error_sqrt (y_test, y_pred):\n",
    "    return np.sqrt((np.sum(np.power(y_test - y_pred, 2)))/len(y_test))\n",
    "def mean_absolute_error_self_defined (y_test, y_pred):\n",
    "    return np.sum(np.abs(y_test - y_pred))/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5de0ea",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa8c2c1",
   "metadata": {},
   "source": [
    "## Importing loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc5cc906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error,mean_absolute_error, mean_squared_error, d2_tweedie_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a620d7",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e23d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test, scaler, model_name):\n",
    "    y_pred_scaled = model.fit(X_train, y_train).predict(X_test)\n",
    "    y_pred = rescale_data(scaler, y_pred_scaled)\n",
    "    y_test_rescaled = rescale_data(scaler, y_test)\n",
    "\n",
    "    # deviding by 10:\n",
    "    y_pred /= 10\n",
    "    y_test_rescaled /= 10\n",
    "\n",
    "    \n",
    "    mae = mean_absolute_error_self_defined (y_test_rescaled, y_pred)\n",
    "    mse = mean_square_error_sqrt(y_test_rescaled, y_pred)\n",
    "    # mape = mean_absolute_percentage_error(y_test_rescaled, y_pred)\n",
    "    # rmse = mean_squared_error(y_test_rescaled, y_pred, squared=False)\n",
    "\n",
    "    print(f\"Evaluating {model_name}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MSE: {mse}\")\n",
    "    # print(f\"MAPE: {mape}\")\n",
    "    # print(f\"RMSE: {rmse}\")\n",
    "    # print(y_test_rescaled.type)\n",
    "    print()\n",
    "    print(\"Y_test:\")\n",
    "    print(y_test_rescaled[:10])\n",
    "    print(\"Y_pred:\")\n",
    "    print(y_pred[:10])\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # plt.plot(np.arange(len(y_pred)), y_pred, label='Predicted')\n",
    "    # plt.plot(np.arange(len(y_pred)), y_test_rescaled, alpha=0.6, label='True')\n",
    "    # plt.title(f\"{model_name} Predictions vs True Values\")\n",
    "    # plt.legend()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ddbc7",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b293cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96be8f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kia/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVR (rbf)\n",
      "MAE: 2122.807113167494\n",
      "MSE: 2561.145374187262\n",
      "\n",
      "Y_test:\n",
      "[3.6000e+00 7.2198e+03 3.3600e+01 6.3500e+01 3.1400e+01 3.8900e+01\n",
      " 0.0000e+00 9.4700e+01 7.4700e+01 2.1166e+03]\n",
      "Y_pred:\n",
      "[ 1123.8884186   5163.17726779 -1691.07791568  -643.97556179\n",
      "  3111.556483    3058.71310399  4361.75938726  -521.22916114\n",
      "  3885.20390206   163.85044334]\n",
      "Evaluating SVR (linear)\n",
      "MAE: 365722.6127873043\n",
      "MSE: 366311.52536822995\n",
      "\n",
      "Y_test:\n",
      "[3.6000e+00 7.2198e+03 3.3600e+01 6.3500e+01 3.1400e+01 3.8900e+01\n",
      " 0.0000e+00 9.4700e+01 7.4700e+01 2.1166e+03]\n",
      "Y_pred:\n",
      "[355828.30601359 361783.57512209 354629.86934506 352732.94632289\n",
      " 354006.14206784 352966.04225913 355557.55798945 354642.59763536\n",
      " 404475.90866142 354417.86592499]\n",
      "Evaluating SVR (poly)\n",
      "MAE: 374298.7171622779\n",
      "MSE: 374717.545660939\n",
      "\n",
      "Y_test:\n",
      "[3.6000e+00 7.2198e+03 3.3600e+01 6.3500e+01 3.1400e+01 3.8900e+01\n",
      " 0.0000e+00 9.4700e+01 7.4700e+01 2.1166e+03]\n",
      "Y_pred:\n",
      "[363967.94169601 369643.19816453 362987.60584412 361339.21074755\n",
      " 362548.0101547  369357.06096926 371340.72119402 362934.89778261\n",
      " 406626.32877553 362984.13320611]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kia/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/kia/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate SVR models\n",
    "svrs = [SVR(kernel=\"rbf\", C=50, gamma=0.9, epsilon=0.001),\n",
    "        SVR(kernel=\"linear\", C=100, gamma=\"auto\"),\n",
    "        SVR(kernel=\"poly\", C=100, gamma=\"auto\", degree=3, epsilon=0.1, coef0=1)]\n",
    "\n",
    "for svr in svrs:\n",
    "    evaluate_model(svr, X_tr, y_tr, X_val, y_val, min_max_scaler_Y, model_name=f\"SVR ({svr.kernel})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b2cda",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea4035e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d681fc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNeighborsRegressor\n",
      "MAE: 506.6818376068376\n",
      "MSE: 1788.2716983926352\n",
      "\n",
      "Y_test:\n",
      "[ 27.3  10.5  40.6  43.8  62.7  65.7  97.2  92.  110.1 143.5]\n",
      "Y_pred:\n",
      "[ 16.85  28.65  92.45  13.75  13.75  22.65 208.95 133.1  386.7  386.7 ]\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate KNeighborsRegressor model\n",
    "neigh = KNeighborsRegressor(n_neighbors=2, p=2)\n",
    "evaluate_model(neigh, X_tr, y_tr, X_te, y_te, min_max_scaler_Y, model_name=\"KNeighborsRegressor\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e572c091",
   "metadata": {},
   "source": [
    "## Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52e76d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "468f8466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kia/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Polynomial Regression\n",
      "MAE: 46.87033423509543\n",
      "MSE: 124.53693744684797\n",
      "\n",
      "Y_test:\n",
      "[ 27.3  10.5  40.6  43.8  62.7  65.7  97.2  92.  110.1 143.5]\n",
      "Y_pred:\n",
      "[  7.72651021  -8.02528545  16.38545864  21.40789511  38.0327891\n",
      "  40.41368189 126.18954868 113.49023137 141.45102646 173.82930481]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kia/.local/lib/python3.11/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly_tr = poly.fit_transform(X_tr)\n",
    "X_poly_te = poly.transform(X_te)\n",
    "\n",
    "linear_model = LinearSVR(dual=\"auto\", random_state=42)\n",
    "evaluate_model(linear_model, X_poly_tr, y_tr, X_poly_te, y_te, min_max_scaler_Y, model_name=\"Polynomial Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbec15c",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2fdc4e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "363013d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kia/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AdaBoostRegressor\n",
      "MAE: 2546.0747916946098\n",
      "MSE: 3900.1011898066135\n",
      "\n",
      "Y_test:\n",
      "[ 27.3  10.5  40.6  43.8  62.7  65.7  97.2  92.  110.1 143.5]\n",
      "Y_pred:\n",
      "[2501.71635148 2501.71635148 2501.71635148 2501.71635148 2501.71635148\n",
      " 2501.71635148 2501.71635148 2501.71635148 2501.71635148 2501.71635148]\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate AdaBoostRegressor model\n",
    "regr = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "evaluate_model(regr, X_tr, y_tr, X_te, y_te, min_max_scaler_Y, model_name=\"AdaBoostRegressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c200fb6",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5ff86613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15a9a8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kia/.local/lib/python3.11/site-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RandomForestRegressor\n",
      "MAE: 455.9947120995119\n",
      "MSE: 751.0454963440693\n",
      "\n",
      "Y_test:\n",
      "[ 27.3  10.5  40.6  43.8  62.7  65.7  97.2  92.  110.1 143.5]\n",
      "Y_pred:\n",
      "[308.58380774 308.58380774 308.58380774 308.58380774 308.58380774\n",
      " 308.58380774 308.58380774 308.58380774 308.58380774 308.58380774]\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate RandomForestRegressor model\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "evaluate_model(regr, X_tr, y_tr, X_te, y_te, min_max_scaler_Y, model_name=\"RandomForestRegressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884bd95",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7342c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40b8cace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kia/.local/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:970: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/kia/.local/lib/python3.11/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/kia/.local/lib/python3.11/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating StackingRegressor\n",
      "MAE: 22.143143083224654\n",
      "MSE: 67.15826408618388\n",
      "\n",
      "Y_test:\n",
      "[ 27.3  10.5  40.6  43.8  62.7  65.7  97.2  92.  110.1 143.5]\n",
      "Y_pred:\n",
      "[ 13.62274656  13.62274656  13.62274656  13.62274656  13.62274656\n",
      "  13.62274656  72.25065755  23.04662252  85.643296   143.14166667]\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate StackingRegressor model\n",
    "estimators = [('lr', RidgeCV()), ('svr', LinearSVR(dual=\"auto\", random_state=42))]\n",
    "reg = StackingRegressor(estimators=estimators,\n",
    "                        final_estimator=RandomForestRegressor(n_estimators=10, random_state=42))\n",
    "evaluate_model(reg, X_tr, y_tr, X_te, y_te, min_max_scaler_Y, model_name=\"StackingRegressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62cadd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample scaled values: [array([0.]), array([4.20007403e-07]), array([4.44713721e-06])]\n",
      "Rescaled values: [  0.  17. 180.]\n",
      "Original values: [0.0, 17.0, 180.0]\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "#check to see if my rescaling is working as intended\n",
    "\n",
    "# Test scaling and rescaling\n",
    "sample_y = [y_scaled[0], y_scaled[10], y_scaled[100]]\n",
    "print(\"Sample scaled values:\", sample_y)\n",
    "\n",
    "rescaled_y = rescale_data(min_max_scaler_Y, sample_y)\n",
    "print(\"Rescaled values:\", rescaled_y)\n",
    "\n",
    "original_y = [Y_list[0], Y_list[10], Y_list[100]]\n",
    "print(\"Original values:\", original_y)\n",
    "\n",
    "# Check if rescaled values match the original values\n",
    "print(\"Match:\", np.allclose(rescaled_y, original_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd6b38f",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "55795a1b-aaa3-4763-b1fe-d0c4e23a7c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ns_list, train_scores, validation_scores = learning_curve(\n",
    "#                                                    estimator = SVR(**opt_svr_param), \n",
    "#                                                    X = X, y = Y, \n",
    "#                                                    train_sizes = ns_list, cv = 5,\n",
    "#                                                    scoring = 'neg_mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ad2e7ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_scores, valid_scores = validation_curve(KNeighborsRegressor(), X, Y, \n",
    "#                                               param_name=\"n_neighbors\",\n",
    "#                                               param_range=k_list , cv=20, \n",
    "#                                               scoring = 'neg_mean_squared_error',\n",
    "#                                               verbose=1, n_jobs=-1\n",
    "#                                              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c424a7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
