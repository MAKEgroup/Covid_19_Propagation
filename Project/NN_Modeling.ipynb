{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c702f1e-ceb6-40a9-98e6-6bac05cf608b",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    color: blue; /* Text color */\n",
    "    background-color: #f0f0f0; /* Light grey background */\n",
    "    font-family: 'Pacifico', cursive; /* Stylish font */\n",
    "    font-size: 40px; /* Font size */\n",
    "    font-weight: bold; /* Bold text */\n",
    "    padding: 20px; /* Padding around the text */\n",
    "    border: 2px solid #ccc; /* Border with a light grey color */\n",
    "    border-radius: 10px; /* Rounded corners */\n",
    "    text-align: center; /* Centered text */\n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); /* Subtle shadow */\n",
    "    position: relative; /* Required for pseudo-elements positioning */\n",
    "    display: inline-block; /* Inline-block for proper spacing */\n",
    "\">\n",
    "    <span style=\"\n",
    "        position: absolute; /* Absolute positioning */\n",
    "        left: -40px; /* Positioning arrow on the left */\n",
    "        top: 50%; /* Vertically center */\n",
    "        transform: translateY(-50%); /* Adjust vertical alignment */\n",
    "        font-size: 30px; /* Arrow size */\n",
    "        color: red; /* Arrow color */\n",
    "    \">➤</span>\n",
    "    NN Modeling\n",
    "    <span style=\"\n",
    "        position: absolute; /* Absolute positioning */\n",
    "        right: -40px; /* Positioning arrow on the right */\n",
    "        top: 50%; /* Vertically center */\n",
    "        transform: translateY(-50%); /* Adjust vertical alignment */\n",
    "        font-size: 30px; /* Arrow size */\n",
    "        color: red; /* Arrow color */\n",
    "    \">➤</span>\n",
    "</div>\n",
    "\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Pacifico&display=swap\" rel=\"stylesheet\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08ff5632-ae6c-44d0-bb6a-ac2063bb5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e5b5316f-b76c-4d1f-8de2-32ea409f2473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
    "prediction_days_count = 2\n",
    "\n",
    "def get_X_Y (exception_countries = []):\n",
    "    df = pd.read_csv(\"../Data/Raw/new_approach/Weekly_Covid_Data.csv\")\n",
    "\n",
    "    # delete called countries:\n",
    "    for iso_code in exception_countries:\n",
    "        df = df[df[\"iso_code\"] != iso_code]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    country_num = int(len(df[\"iso_code\"].unique()))\n",
    "    \n",
    "    df.drop([\"iso_code\", \"week_no\"], axis=1, inplace=True)\n",
    "    #df.drop(columns=df.columns[0:1], axis=1, inplace=True)\n",
    "    pop = df.iloc[0][\"population\"]\n",
    "    last_country = df.iloc[country_num*176 - 1]\n",
    "    print(last_country)\n",
    "    cnt = df[\"population\"].value_counts()\n",
    "    \n",
    "    # now we want to join datas together\n",
    "    features_list = []\n",
    "    X_list = []\n",
    "    Y_list = []\n",
    "    \n",
    "    for i in range(country_num):  # 234 is number of countries\n",
    "        for j in range(176):  # 176 is number of weeks we have\n",
    "            row_list = df.loc[i * 176 + j, :].values.flatten().tolist()\n",
    "            features_list.append(row_list)\n",
    "    \n",
    "    for i in range((len(features_list) - prediction_days_count) + 1):\n",
    "        fl = features_list[i]\n",
    "        fl_len = len(features_list[i])\n",
    "        this_population = features_list[i][fl_len - 1]\n",
    "        for j in range(1, prediction_days_count):\n",
    "            if this_population == features_list[i + j][fl_len - 1]:\n",
    "                fl.extend(features_list[i + j])\n",
    "            else:\n",
    "                this_population = -1\n",
    "                break\n",
    "        if this_population != -1:\n",
    "            X_list.append(fl)\n",
    "            Y_list.append(features_list[(i + prediction_days_count) - 1][0])\n",
    "        \n",
    "    return X_list, Y_list, country_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7aee7c8a-f8cf-45f1-bd7e-a830c48d3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def train_test_splitter(X, Y, country_num, prediction_days_count, batch_count, batch_length):\n",
    "    xlen = len(X)\n",
    "    xs_count_for_each_country = int(xlen / country_num)\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    Y_train = []\n",
    "    Y_test = []\n",
    "    steps = math.floor((xs_count_for_each_country - (batch_count * batch_length)) / (batch_count + 1)) \n",
    "    i = 0\n",
    "    for i in range(country_num):\n",
    "        j = 0\n",
    "        for j in range((i * xs_count_for_each_country), (i * xs_count_for_each_country) + steps):\n",
    "            X_train.append(X[j])\n",
    "            Y_train.append(Y[j])\n",
    "        while(j + batch_length + steps < (i+1) * xs_count_for_each_country):\n",
    "            for k in range(j + prediction_days_count, j + batch_length - prediction_days_count):\n",
    "                X_test.append(X[k])\n",
    "                Y_test.append(Y[k])\n",
    "            j += batch_length\n",
    "            for k in range(j, j + steps):\n",
    "                X_train.append(X[k])\n",
    "                Y_train.append(Y[k])\n",
    "            j += steps + 1\n",
    "            while j < (i+1) * xs_count_for_each_country:\n",
    "                X_train.append(X[j])\n",
    "                Y_train.append(Y[j])\n",
    "                j += 1\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f494b1db-6b17-47c1-990e-7fe83441fb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_cases                     7.500000e+01\n",
      "new_deaths                    2.000000e+00\n",
      "new_vaccinations              0.000000e+00\n",
      "new_people_vaccinated         0.000000e+00\n",
      "reproduction_rate             9.500000e-01\n",
      "stringency_index              8.796000e+01\n",
      "excess_mortality             -1.000000e+03\n",
      "population_density            4.272900e+01\n",
      "median_age                    1.960000e+01\n",
      "aged_65_older                 2.822000e+00\n",
      "aged_70_older                 1.882000e+00\n",
      "cardiovasc_death_rate         3.078460e+02\n",
      "diabetes_prevalence           1.820000e+00\n",
      "female_smokers                1.600000e+00\n",
      "male_smokers                  3.070000e+01\n",
      "hospital_beds_per_thousand    1.700000e+00\n",
      "life_expectancy               6.149000e+01\n",
      "human_development_index       5.710000e-01\n",
      "population                    1.632054e+07\n",
      "Name: 41007, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# getting data:\n",
    "X_list, Y_list, country_num = get_X_Y([\"CHN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "065c3929-721c-4104-ad91-98b0a31c49c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = pd.DataFrame(X_list)\n",
    "min_max_scaler_X = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler_X.fit_transform(x_df)\n",
    "\n",
    "y_df = pd.DataFrame(Y_list)\n",
    "min_max_scaler_Y = preprocessing.MinMaxScaler()\n",
    "y_scaled = min_max_scaler_Y.fit_transform(y_df)\n",
    "\n",
    "X_scaled_list = x_scaled.tolist()\n",
    "Y_scaled_list = y_scaled.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e1782c1c-826e-404d-b797-1aed5caec7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_splitter(X_scaled_list, Y_scaled_list,\n",
    "                                                       country_num=country_num,\n",
    "                                                       prediction_days_count=prediction_days_count,\n",
    "                                                       batch_count=3,\n",
    "                                                       batch_length=10)\n",
    "X_tr = np.array(X_train)\n",
    "y_tr = np.array(Y_train).reshape(len(Y_train))\n",
    "X_te = np.array(X_test)\n",
    "y_te = np.array(Y_test).reshape(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1ff82d87-2d9e-4651-bc27-7a1c090d8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = min_max_scaler_Y.data_min_[0]\n",
    "max_val = min_max_scaler_Y.data_max_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "420b5446-f529-4779-8b3c-9675e9b5751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Define the custom loss function\n",
    "\n",
    "\n",
    "# Define the custom loss function\n",
    "def rescale_data_tensor(data):\n",
    "    return (data * (max_val - min_val) + min_val)/10 # you can delete /10 I put it because we add 10 people\n",
    "                                                     # error \n",
    "    \n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = rescale_data_tensor(y_true)\n",
    "    y_pred = rescale_data_tensor(y_pred)\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b849e41-fa68-4047-8bc8-4364ca71d294",
   "metadata": {},
   "source": [
    "# First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "36c68435-f246-4027-aac0-7db34539f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modle_1 = keras.Sequential([\n",
    "    keras.Input(shape=(X_tr.shape[1],)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(1)  # No activation function for regression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "848b58cc-e34d-48fd-83bb-c367a50cb2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modle_1.compile(optimizer='adam',\n",
    "              loss=loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9e1324f2-1fce-4921-acbf-ce54ec330dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,561</span> (10.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,561\u001b[0m (10.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,561</span> (10.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,561\u001b[0m (10.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modle_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "72f9e2c0-ddd1-4edd-a6c1-c25e35e74d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 930us/step - loss: 19538.1309 - val_loss: 9768.6650\n",
      "Epoch 2/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 3962.0684 - val_loss: 8826.1230\n",
      "Epoch 3/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 3047.3418 - val_loss: 8629.0020\n",
      "Epoch 4/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 2428.6196 - val_loss: 8976.9238\n",
      "Epoch 5/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 2693.8110 - val_loss: 7920.3096\n",
      "Epoch 6/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 2870.8452 - val_loss: 6905.6445\n",
      "Epoch 7/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 2515.3303 - val_loss: 10402.8145\n",
      "Epoch 8/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 3558.6689 - val_loss: 6593.0298\n",
      "Epoch 9/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 2223.8696 - val_loss: 6650.5957\n",
      "Epoch 10/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 2641.7146 - val_loss: 7626.2295\n",
      "Epoch 11/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 2991.7688 - val_loss: 5873.9414\n",
      "Epoch 12/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 2378.2644 - val_loss: 6482.9214\n",
      "Epoch 13/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 1931.6454 - val_loss: 6667.9312\n",
      "Epoch 14/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 1917.2935 - val_loss: 10408.7578\n",
      "Epoch 15/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 2853.5569 - val_loss: 7186.3853\n",
      "Epoch 16/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 2272.2710 - val_loss: 7058.8496\n",
      "Epoch 17/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - loss: 2769.6333 - val_loss: 6779.5854\n",
      "Epoch 18/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 1986.3002 - val_loss: 7241.1162\n",
      "Epoch 19/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 1706.1578 - val_loss: 4767.0420\n",
      "Epoch 20/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 2098.2051 - val_loss: 5216.6694\n",
      "Epoch 21/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 2075.2529 - val_loss: 6172.5063\n",
      "Epoch 22/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 2397.0527 - val_loss: 5989.6948\n",
      "Epoch 23/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 1624.8525 - val_loss: 4406.0913\n",
      "Epoch 24/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 1671.0999 - val_loss: 4488.2241\n",
      "Epoch 25/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 1917.1663 - val_loss: 5602.4463\n",
      "Epoch 26/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 1878.1287 - val_loss: 4151.4160\n",
      "Epoch 27/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 2115.0220 - val_loss: 3928.6543\n",
      "Epoch 28/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 1268.4576 - val_loss: 4175.1621\n",
      "Epoch 29/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 1476.4928 - val_loss: 5000.7417\n",
      "Epoch 30/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 1264.8864 - val_loss: 4636.2939\n",
      "Epoch 31/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 1185.6807 - val_loss: 3620.4021\n",
      "Epoch 32/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 1083.9133 - val_loss: 4645.5557\n",
      "Epoch 33/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 1345.0911 - val_loss: 4349.9580\n",
      "Epoch 34/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 1119.3392 - val_loss: 3417.5771\n",
      "Epoch 35/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 1157.1598 - val_loss: 4302.6011\n",
      "Epoch 36/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 1126.3033 - val_loss: 3741.1248\n",
      "Epoch 37/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 1057.5598 - val_loss: 3992.9697\n",
      "Epoch 38/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 1169.2474 - val_loss: 3263.3657\n",
      "Epoch 39/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 1057.9829 - val_loss: 5138.4014\n",
      "Epoch 40/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 1235.1993 - val_loss: 3651.0461\n",
      "Epoch 41/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 1259.7367 - val_loss: 3769.0366\n",
      "Epoch 42/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 1043.2102 - val_loss: 3231.4480\n",
      "Epoch 43/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 1560.4293 - val_loss: 3773.8677\n",
      "Epoch 44/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 919.5001 - val_loss: 3142.5745\n",
      "Epoch 45/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 1243.0576 - val_loss: 3180.2786\n",
      "Epoch 46/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 1234.6765 - val_loss: 2786.4050\n",
      "Epoch 47/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 1186.5575 - val_loss: 2844.6707\n",
      "Epoch 48/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 1194.8120 - val_loss: 3302.6409\n",
      "Epoch 49/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 1019.3475 - val_loss: 3459.0188\n",
      "Epoch 50/50\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 1164.3715 - val_loss: 2807.6521\n"
     ]
    }
   ],
   "source": [
    "history = modle_1.fit(X_tr, y_tr, validation_split=0.25, epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "47d839a0-c702-4656-867c-b3ef9e739abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "y_pred = modle_1.predict (X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d539a1de-6060-49e0-873d-534aae4d2139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=7658.91743214217>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(y_te, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfba8e3-c7a3-4176-a525-b4338f97c819",
   "metadata": {},
   "source": [
    "# Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "13eaffa1-ddaf-4cdc-95b8-d03c468a9cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = keras.Sequential([\n",
    "    keras.Input(shape=(X_tr.shape[1],)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)  # No activation function for regression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "95a89f24-4734-4bb1-bc67-a7341672f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer='adam',\n",
    "              loss=loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "78fd7d58-8d75-4a36-8c26-058762889dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,361</span> (60.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,361\u001b[0m (60.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,361</span> (60.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,361\u001b[0m (60.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dd0ba131-71e6-4ecd-bc56-b35d44bf8703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 10132.6973 - val_loss: 5917.3799\n",
      "Epoch 2/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - loss: 2826.5164 - val_loss: 6077.2837\n",
      "Epoch 3/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - loss: 2293.6726 - val_loss: 2592.9077\n",
      "Epoch 4/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - loss: 1711.3815 - val_loss: 1853.5065\n",
      "Epoch 5/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step - loss: 1567.0398 - val_loss: 2212.0449\n",
      "Epoch 6/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - loss: 1291.7601 - val_loss: 4934.8613\n",
      "Epoch 7/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - loss: 1457.3086 - val_loss: 1613.1071\n",
      "Epoch 8/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - loss: 1021.5228 - val_loss: 1743.0806\n",
      "Epoch 9/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - loss: 926.3903 - val_loss: 1350.9608\n",
      "Epoch 10/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - loss: 869.9085 - val_loss: 2575.2805\n",
      "Epoch 11/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - loss: 911.7292 - val_loss: 1153.8180\n",
      "Epoch 12/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - loss: 905.3820 - val_loss: 1186.9803\n",
      "Epoch 13/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - loss: 782.4750 - val_loss: 2778.7852\n",
      "Epoch 14/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - loss: 862.0798 - val_loss: 1423.5708\n",
      "Epoch 15/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - loss: 897.6750 - val_loss: 876.6217\n",
      "Epoch 16/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - loss: 715.7188 - val_loss: 1215.4110\n",
      "Epoch 17/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930us/step - loss: 668.7045 - val_loss: 1631.7356\n",
      "Epoch 18/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - loss: 765.8209 - val_loss: 974.7148\n",
      "Epoch 19/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - loss: 666.1707 - val_loss: 757.1328\n",
      "Epoch 20/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930us/step - loss: 588.0820 - val_loss: 713.9993\n",
      "Epoch 21/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - loss: 579.9623 - val_loss: 745.0759\n",
      "Epoch 22/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - loss: 551.5802 - val_loss: 687.8959\n",
      "Epoch 23/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - loss: 504.3734 - val_loss: 870.4523\n",
      "Epoch 24/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - loss: 569.5508 - val_loss: 640.3716\n",
      "Epoch 25/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - loss: 512.0737 - val_loss: 674.9411\n",
      "Epoch 26/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - loss: 516.3591 - val_loss: 986.2584\n",
      "Epoch 27/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - loss: 503.3185 - val_loss: 1801.0414\n",
      "Epoch 28/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - loss: 582.3692 - val_loss: 1876.1252\n",
      "Epoch 29/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - loss: 572.5724 - val_loss: 791.9482\n",
      "Epoch 30/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - loss: 478.9124 - val_loss: 804.7517\n",
      "Epoch 31/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 977us/step - loss: 409.7320 - val_loss: 850.3166\n",
      "Epoch 32/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - loss: 450.7370 - val_loss: 739.5349\n",
      "Epoch 33/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - loss: 431.5090 - val_loss: 743.3076\n",
      "Epoch 34/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - loss: 423.2764 - val_loss: 1204.0388\n",
      "Epoch 35/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - loss: 457.5726 - val_loss: 688.2692\n",
      "Epoch 36/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - loss: 438.1325 - val_loss: 705.0665\n",
      "Epoch 37/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - loss: 428.7529 - val_loss: 1166.2212\n",
      "Epoch 38/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - loss: 486.0262 - val_loss: 843.9025\n",
      "Epoch 39/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - loss: 423.0597 - val_loss: 570.1129\n",
      "Epoch 40/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - loss: 395.5087 - val_loss: 590.1604\n",
      "Epoch 41/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - loss: 410.9021 - val_loss: 1121.0425\n",
      "Epoch 42/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - loss: 358.2867 - val_loss: 619.4365\n",
      "Epoch 43/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - loss: 390.1158 - val_loss: 621.0869\n",
      "Epoch 44/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - loss: 350.9090 - val_loss: 518.7551\n",
      "Epoch 45/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - loss: 378.1911 - val_loss: 559.0878\n",
      "Epoch 46/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - loss: 394.5746 - val_loss: 717.9315\n",
      "Epoch 47/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - loss: 382.0049 - val_loss: 575.5208\n",
      "Epoch 48/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - loss: 389.6870 - val_loss: 564.4395\n",
      "Epoch 49/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - loss: 400.9540 - val_loss: 612.8888\n",
      "Epoch 50/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - loss: 372.9118 - val_loss: 749.0845\n",
      "Epoch 51/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - loss: 481.5982 - val_loss: 738.4914\n",
      "Epoch 52/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - loss: 357.8334 - val_loss: 713.4057\n",
      "Epoch 53/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - loss: 372.9154 - val_loss: 828.3951\n",
      "Epoch 54/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - loss: 356.8770 - val_loss: 534.6124\n",
      "Epoch 55/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - loss: 385.5078 - val_loss: 492.5737\n",
      "Epoch 56/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - loss: 337.8347 - val_loss: 620.0887\n",
      "Epoch 57/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - loss: 411.4178 - val_loss: 789.5605\n",
      "Epoch 58/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - loss: 399.1943 - val_loss: 485.7557\n",
      "Epoch 59/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - loss: 351.7546 - val_loss: 678.1577\n",
      "Epoch 60/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - loss: 368.4387 - val_loss: 596.3629\n",
      "Epoch 61/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - loss: 365.9927 - val_loss: 611.3571\n",
      "Epoch 62/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - loss: 337.2893 - val_loss: 702.1046\n",
      "Epoch 63/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - loss: 280.3980 - val_loss: 488.4695\n",
      "Epoch 64/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - loss: 323.9198 - val_loss: 465.6042\n",
      "Epoch 65/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - loss: 317.6911 - val_loss: 573.1122\n",
      "Epoch 66/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - loss: 342.6679 - val_loss: 526.9404\n",
      "Epoch 67/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - loss: 298.3612 - val_loss: 854.4323\n",
      "Epoch 68/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - loss: 370.1562 - val_loss: 505.8319\n",
      "Epoch 69/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - loss: 311.6530 - val_loss: 452.1296\n",
      "Epoch 70/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - loss: 293.7262 - val_loss: 661.4008\n",
      "Epoch 71/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - loss: 395.2837 - val_loss: 428.9231\n",
      "Epoch 72/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - loss: 314.9472 - val_loss: 564.0206\n",
      "Epoch 73/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - loss: 360.7646 - val_loss: 528.5616\n",
      "Epoch 74/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - loss: 342.1255 - val_loss: 383.5720\n",
      "Epoch 75/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - loss: 342.8036 - val_loss: 596.1653\n",
      "Epoch 76/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - loss: 296.8053 - val_loss: 820.0707\n",
      "Epoch 77/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - loss: 312.9053 - val_loss: 488.7661\n",
      "Epoch 78/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - loss: 312.8284 - val_loss: 384.0155\n",
      "Epoch 79/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - loss: 281.0153 - val_loss: 399.2833\n",
      "Epoch 80/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - loss: 286.7622 - val_loss: 830.6064\n",
      "Epoch 81/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - loss: 305.3737 - val_loss: 533.2571\n",
      "Epoch 82/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - loss: 283.4990 - val_loss: 627.6457\n",
      "Epoch 83/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step - loss: 300.1342 - val_loss: 520.8977\n",
      "Epoch 84/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - loss: 282.1853 - val_loss: 610.7071\n",
      "Epoch 85/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - loss: 326.4391 - val_loss: 582.5569\n",
      "Epoch 86/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - loss: 274.0131 - val_loss: 643.2030\n",
      "Epoch 87/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - loss: 285.8471 - val_loss: 664.5567\n",
      "Epoch 88/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - loss: 309.8456 - val_loss: 391.2740\n",
      "Epoch 89/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - loss: 314.2296 - val_loss: 1120.4351\n",
      "Epoch 90/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - loss: 372.4561 - val_loss: 622.5939\n",
      "Epoch 91/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - loss: 264.5876 - val_loss: 588.9736\n",
      "Epoch 92/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - loss: 304.1458 - val_loss: 549.1942\n",
      "Epoch 93/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - loss: 257.2059 - val_loss: 383.9418\n",
      "Epoch 94/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - loss: 333.1902 - val_loss: 408.7509\n",
      "Epoch 95/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - loss: 332.5729 - val_loss: 391.1661\n",
      "Epoch 96/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - loss: 255.7084 - val_loss: 413.4482\n",
      "Epoch 97/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 231.5103 - val_loss: 346.5273\n",
      "Epoch 98/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - loss: 278.0293 - val_loss: 713.6452\n",
      "Epoch 99/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - loss: 269.3142 - val_loss: 740.5241\n",
      "Epoch 100/100\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - loss: 281.5477 - val_loss: 409.4934\n"
     ]
    }
   ],
   "source": [
    "history = model_2.fit(X_tr, y_tr, validation_split=0.25, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8ae1b7f9-d8eb-4bda-99ed-0cfe6c2bf2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=6586.99384925401>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_2.predict (X_te)\n",
    "loss_function(y_te, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060d3e29-d0f8-4ce9-8988-826dcd2df70e",
   "metadata": {},
   "source": [
    "# Third Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "66a787b6-f5b3-4c5f-8b54-1d0af756623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_reshaped = X_tr.reshape(X_tr.shape[0], X_tr.shape[1], 1)\n",
    "X_te_reshaped = X_te.reshape(X_te.shape[0], X_te.shape[1], 1)\n",
    "\n",
    "model_3 = keras.Sequential([\n",
    "    keras.Input(shape=(X_tr.shape[1], 1)),\n",
    "    keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Conv1D(32, kernel_size=3, activation='relu'),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='leaky_relu'),\n",
    "    keras.layers.Dense(1)  # No activation function for regression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2466c253-9e75-4cd8-90d6-58d3c8ddb21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(optimizer='adam',\n",
    "              loss=loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b55df0ae-7d39-463e-9199-03cfb11c61ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m6,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,945</span> (89.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,945\u001b[0m (89.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,945</span> (89.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,945\u001b[0m (89.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9934e987-3f0b-46ef-92fb-67b4f771fcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7368.5303 - val_loss: 3521.8357\n",
      "Epoch 2/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3277.4753 - val_loss: 3314.4783\n",
      "Epoch 3/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1853.2959 - val_loss: 2386.3096\n",
      "Epoch 4/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1222.5406 - val_loss: 1643.0807\n",
      "Epoch 5/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1079.8007 - val_loss: 2017.6349\n",
      "Epoch 6/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 956.7016 - val_loss: 1146.9729\n",
      "Epoch 7/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 913.5614 - val_loss: 3086.8528\n",
      "Epoch 8/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1036.4404 - val_loss: 1543.5526\n",
      "Epoch 9/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 890.6574 - val_loss: 982.8900\n",
      "Epoch 10/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 710.0589 - val_loss: 1215.3370\n",
      "Epoch 11/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 723.6082 - val_loss: 1579.5765\n",
      "Epoch 12/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 816.1663 - val_loss: 1505.4200\n",
      "Epoch 13/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 686.5025 - val_loss: 838.5103\n",
      "Epoch 14/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 699.6199 - val_loss: 862.5504\n",
      "Epoch 15/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 734.3871 - val_loss: 1095.1422\n",
      "Epoch 16/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 673.4674 - val_loss: 1463.7150\n",
      "Epoch 17/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 625.0305 - val_loss: 1038.0586\n",
      "Epoch 18/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 603.0353 - val_loss: 1038.5912\n",
      "Epoch 19/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 563.0127 - val_loss: 1011.9536\n",
      "Epoch 20/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.0891 - val_loss: 1221.5143\n",
      "Epoch 21/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 619.7267 - val_loss: 1088.3335\n",
      "Epoch 22/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 594.2783 - val_loss: 1075.1064\n",
      "Epoch 23/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 560.4761 - val_loss: 1285.6658\n",
      "Epoch 24/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 593.2591 - val_loss: 997.9144\n",
      "Epoch 25/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 568.2219 - val_loss: 1380.8157\n",
      "Epoch 26/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 574.6188 - val_loss: 998.8110\n",
      "Epoch 27/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 524.6355 - val_loss: 868.4241\n",
      "Epoch 28/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 593.0150 - val_loss: 924.7797\n",
      "Epoch 29/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 501.3275 - val_loss: 980.3058\n",
      "Epoch 30/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 550.7457 - val_loss: 860.0505\n",
      "Epoch 31/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 483.1506 - val_loss: 999.8919\n",
      "Epoch 32/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 453.7433 - val_loss: 935.9052\n",
      "Epoch 33/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 508.5536 - val_loss: 848.1079\n",
      "Epoch 34/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 472.4561 - val_loss: 746.7817\n",
      "Epoch 35/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 495.3068 - val_loss: 922.3005\n",
      "Epoch 36/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 480.9684 - val_loss: 1197.6365\n",
      "Epoch 37/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 534.8090 - val_loss: 1026.2128\n",
      "Epoch 38/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 529.6144 - val_loss: 1056.8574\n",
      "Epoch 39/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 545.4037 - val_loss: 845.1883\n",
      "Epoch 40/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 486.8022 - val_loss: 859.3361\n",
      "Epoch 41/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 432.9021 - val_loss: 1176.9904\n",
      "Epoch 42/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 571.3000 - val_loss: 783.6692\n",
      "Epoch 43/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 435.3828 - val_loss: 1253.2236\n",
      "Epoch 44/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 497.0555 - val_loss: 1089.1346\n",
      "Epoch 45/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 499.5883 - val_loss: 800.0516\n",
      "Epoch 46/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 482.8121 - val_loss: 806.3607\n",
      "Epoch 47/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 450.1457 - val_loss: 992.0132\n",
      "Epoch 48/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 487.0209 - val_loss: 768.9597\n",
      "Epoch 49/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 513.7806 - val_loss: 793.9942\n",
      "Epoch 50/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 431.4756 - val_loss: 984.1146\n"
     ]
    }
   ],
   "source": [
    "history = model_3.fit(X_tr_reshaped, y_tr, validation_split=0.25, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dfcd57bb-0ac9-4b8e-be1d-8a7b81efcb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=6565.8024041816425>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_3.predict (X_te)\n",
    "loss_function(y_te, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d0f1a6-4563-4b96-9be7-5c7452ef9018",
   "metadata": {},
   "source": [
    "# Forth Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "df699d3e-0772-456e-aa86-b301777ab93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_reshaped = X_tr.reshape(X_tr.shape[0], X_tr.shape[1], 1)\n",
    "X_te_reshaped = X_te.reshape(X_te.shape[0], X_te.shape[1], 1)\n",
    "\n",
    "model_4 = keras.Sequential([\n",
    "    keras.Input(shape=(X_tr.shape[1], 1)),\n",
    "    keras.layers.SimpleRNN(64, activation='relu'),\n",
    "    keras.layers.Dense(1)  # No activation function for regression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "922a3593-baa2-4942-b489-fc22ddf391f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(optimizer='adam',\n",
    "              loss=loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b10204e6-e37b-4b05-a83c-c46fed46aa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,289</span> (16.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,289\u001b[0m (16.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,289</span> (16.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,289\u001b[0m (16.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a734f535-84c3-4e6c-9d4c-1799adf02bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6715.2119 - val_loss: 5164.3228\n",
      "Epoch 2/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4815.7139 - val_loss: 5750.4980\n",
      "Epoch 3/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3506.1104 - val_loss: 3905.8457\n",
      "Epoch 4/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2105.2246 - val_loss: 3039.9346\n",
      "Epoch 5/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1810.4463 - val_loss: 2730.8311\n",
      "Epoch 6/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1653.2291 - val_loss: 2977.8538\n",
      "Epoch 7/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1576.2588 - val_loss: 2869.6440\n",
      "Epoch 8/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1580.3351 - val_loss: 2661.3660\n",
      "Epoch 9/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1462.3433 - val_loss: 2644.5703\n",
      "Epoch 10/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1301.3262 - val_loss: 2649.3774\n",
      "Epoch 11/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1433.5942 - val_loss: 3687.0862\n",
      "Epoch 12/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1468.6569 - val_loss: 2468.5120\n",
      "Epoch 13/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1352.6844 - val_loss: 2589.2224\n",
      "Epoch 14/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1328.5249 - val_loss: 2374.0137\n",
      "Epoch 15/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1113.3148 - val_loss: 2861.6204\n",
      "Epoch 16/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1185.0686 - val_loss: 3367.5938\n",
      "Epoch 17/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1526.5525 - val_loss: 2809.1824\n",
      "Epoch 18/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1096.2095 - val_loss: 1768.6700\n",
      "Epoch 19/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 978.5977 - val_loss: 2587.1738\n",
      "Epoch 20/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1230.9954 - val_loss: 1691.3940\n",
      "Epoch 21/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1036.2972 - val_loss: 3781.4021\n",
      "Epoch 22/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1155.5659 - val_loss: 2366.2959\n",
      "Epoch 23/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1024.4757 - val_loss: 2008.2666\n",
      "Epoch 24/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1069.7354 - val_loss: 1712.2266\n",
      "Epoch 25/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1006.7012 - val_loss: 1625.3584\n",
      "Epoch 26/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1071.3914 - val_loss: 1786.3560\n",
      "Epoch 27/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1147.8676 - val_loss: 1947.0083\n",
      "Epoch 28/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 894.5408 - val_loss: 2493.0410\n",
      "Epoch 29/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 907.7304 - val_loss: 1764.7883\n",
      "Epoch 30/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1088.1171 - val_loss: 2024.8899\n",
      "Epoch 31/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 922.8752 - val_loss: 1414.0052\n",
      "Epoch 32/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 932.8124 - val_loss: 1464.0709\n",
      "Epoch 33/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 805.6915 - val_loss: 1876.8588\n",
      "Epoch 34/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 913.7425 - val_loss: 1505.4785\n",
      "Epoch 35/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 846.9946 - val_loss: 1839.0638\n",
      "Epoch 36/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 885.9685 - val_loss: 1664.1641\n",
      "Epoch 37/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 950.2327 - val_loss: 1578.3560\n",
      "Epoch 38/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 955.9907 - val_loss: 1552.7085\n",
      "Epoch 39/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 827.0403 - val_loss: 1734.3860\n",
      "Epoch 40/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 947.3987 - val_loss: 1557.4509\n",
      "Epoch 41/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 867.1036 - val_loss: 2149.4724\n",
      "Epoch 42/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 917.4329 - val_loss: 1570.1262\n",
      "Epoch 43/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 765.0818 - val_loss: 1833.9811\n",
      "Epoch 44/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 733.1435 - val_loss: 2023.4492\n",
      "Epoch 45/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 945.1692 - val_loss: 1947.9915\n",
      "Epoch 46/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 799.9182 - val_loss: 1567.8969\n",
      "Epoch 47/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 796.4298 - val_loss: 1489.4508\n",
      "Epoch 48/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 767.2516 - val_loss: 1496.1138\n",
      "Epoch 49/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 938.7403 - val_loss: 1680.8574\n",
      "Epoch 50/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 826.1372 - val_loss: 1678.8960\n"
     ]
    }
   ],
   "source": [
    "history = model_4.fit(X_tr_reshaped, y_tr, validation_split=0.25, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fda9ead3-ed03-4ec1-8c51-9df837780685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=7488.029311789402>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_4.predict (X_te)\n",
    "loss_function(y_te, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e877d8f6-8423-42e7-9a91-468f839a04b1",
   "metadata": {},
   "source": [
    "# Fifth Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "764042c7-719e-4c92-8430-ef77776e98d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_reshaped = X_tr.reshape(X_tr.shape[0], X_tr.shape[1], 1)\n",
    "X_te_reshaped = X_te.reshape(X_te.shape[0], X_te.shape[1], 1)\n",
    "\n",
    "model_5 = keras.Sequential([\n",
    "    keras.Input(shape=(X_tr.shape[1], 1)),\n",
    "    keras.layers.LSTM(64, activation='relu'),\n",
    "    keras.layers.Dense(1)  # No activation function for regression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "140fd691-311a-4c25-84e7-d0f5d570ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.compile(optimizer='adam',\n",
    "              loss=loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "945a6487-ea7b-4f81-a422-d41dd28938f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,961</span> (66.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,961\u001b[0m (66.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,961</span> (66.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,961\u001b[0m (66.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "19e974ce-bbcb-44af-8611-4a8e8c686e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 5473.9897 - val_loss: 3512.6721\n",
      "Epoch 2/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5021.6865 - val_loss: 3355.4163\n",
      "Epoch 3/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 4162.8149 - val_loss: 3021.9329\n",
      "Epoch 4/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 3479.2500 - val_loss: 2580.7573\n",
      "Epoch 5/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 3310.5261 - val_loss: 2376.0908\n",
      "Epoch 6/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 2302.4231 - val_loss: 2234.1448\n",
      "Epoch 7/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 1689.8063 - val_loss: 1331.8375\n",
      "Epoch 8/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 1314.3998 - val_loss: 1058.6250\n",
      "Epoch 9/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 1410.0973 - val_loss: 1870.1173\n",
      "Epoch 10/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 1233.4760 - val_loss: 1254.5377\n",
      "Epoch 11/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1409.6354 - val_loss: 1996.6134\n",
      "Epoch 12/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 1258.9126 - val_loss: 1079.6533\n",
      "Epoch 13/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 1453.6732 - val_loss: 1136.1555\n",
      "Epoch 14/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 1072.2079 - val_loss: 933.7391\n",
      "Epoch 15/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 1157.7970 - val_loss: 704.8171\n",
      "Epoch 16/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 979.5043 - val_loss: 953.4861\n",
      "Epoch 17/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 1253.7321 - val_loss: 1034.9968\n",
      "Epoch 18/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 1075.3750 - val_loss: 1040.5399\n",
      "Epoch 19/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 1026.9170 - val_loss: 695.5283\n",
      "Epoch 20/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 977.1380 - val_loss: 1087.8368\n",
      "Epoch 21/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 1091.9739 - val_loss: 888.3532\n",
      "Epoch 22/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 1137.2094 - val_loss: 756.1355\n",
      "Epoch 23/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 884.4586 - val_loss: 917.4098\n",
      "Epoch 24/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 980.1444 - val_loss: 1114.9612\n",
      "Epoch 25/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 1000.1129 - val_loss: 759.6706\n",
      "Epoch 26/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 826.4080 - val_loss: 714.1898\n",
      "Epoch 27/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 1122.3613 - val_loss: 937.5740\n",
      "Epoch 28/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 904.7524 - val_loss: 1149.3527\n",
      "Epoch 29/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 830.0891 - val_loss: 789.5566\n",
      "Epoch 30/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 940.0825 - val_loss: 812.8569\n",
      "Epoch 31/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 819.2305 - val_loss: 961.5660\n",
      "Epoch 32/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 893.3942 - val_loss: 904.1304\n",
      "Epoch 33/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 868.6193 - val_loss: 662.5170\n",
      "Epoch 34/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 813.2581 - val_loss: 801.6174\n",
      "Epoch 35/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 745.2830 - val_loss: 1024.4734\n",
      "Epoch 36/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 847.5965 - val_loss: 1305.8142\n",
      "Epoch 37/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 928.9286 - val_loss: 698.3896\n",
      "Epoch 38/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 800.0514 - val_loss: 965.9334\n",
      "Epoch 39/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 875.9755 - val_loss: 1619.6229\n",
      "Epoch 40/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 920.2292 - val_loss: 1013.2581\n",
      "Epoch 41/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 747.2801 - val_loss: 1128.4833\n",
      "Epoch 42/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 829.0768 - val_loss: 863.8894\n",
      "Epoch 43/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 759.6497 - val_loss: 1249.0803\n",
      "Epoch 44/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 850.6273 - val_loss: 1027.8853\n",
      "Epoch 45/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 654.1248 - val_loss: 1079.6747\n",
      "Epoch 46/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 733.7008 - val_loss: 907.9894\n",
      "Epoch 47/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 735.8644 - val_loss: 1010.5072\n",
      "Epoch 48/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 724.5436 - val_loss: 1073.4355\n",
      "Epoch 49/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 749.3325 - val_loss: 851.1837\n",
      "Epoch 50/50\n",
      "\u001b[1m902/902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 740.9786 - val_loss: 728.6502\n"
     ]
    }
   ],
   "source": [
    "history = model_5.fit(X_tr_reshaped, y_tr, validation_split=0.25, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "edf8a976-5044-4ed4-84da-527bd937b9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=6702.900378200025>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_5.predict (X_te)\n",
    "loss_function(tf.convert_to_tensor(y_te), y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
